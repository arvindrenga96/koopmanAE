{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-architect",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'exp_100seed_0.03noise'\n",
    "directory = 'exp_with_changes'\n",
    "dae_pattern = f'../results/{directory}/*/results_det_pendulum_6_noise_08_DAE/000_pred.npy'\n",
    "koopman_AE_pattern = f'../results/{directory}/*/results_det_pendulum_6_noise_08_Koopman_AE/000_pred.npy'\n",
    "INN_pattern= f'../results/{directory}/*/results_det_pendulum_6_noise_08_KOOPMAN_AE_INN/000_pred.npy'\n",
    "RNN_Patten=f'../results/{directory}/*/results_det_pendulum_6_noise_08_RNN_NEW/000_pred.npy'\n",
    "\n",
    "pattern_list= [dae_pattern,koopman_AE_pattern,INN_pattern,RNN_Patten]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(lst, title):\n",
    "    average = statistics.mean(lst)\n",
    "    minimum = min(lst)\n",
    "    maximum = max(lst)\n",
    "    stdev = statistics.stdev(lst)\n",
    "\n",
    "    print(f\" {title } Average:\", average)\n",
    "    print(f\" {title } Minimum:\", minimum)\n",
    "    print(f\"{title } Maximum:\", maximum)\n",
    "    print(f\"{title } Standard Deviation:\", stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_names = [\"DAE\", \"Koopman AE\", \"INN\", \"RNN\"]\n",
    "for index, ind_patter in enumerate(pattern_list):\n",
    "    avg_error = []\n",
    "    last_100_error = []\n",
    "    first_100_error = []\n",
    "\n",
    "    matched_directories = glob.glob(ind_patter)\n",
    "    for dir_path in matched_directories:\n",
    "        pred_file = np.load(dir_path)\n",
    "        avg_error.append(np.mean(pred_file.mean(axis=0)))\n",
    "        last_100_error.append(np.mean(pred_file.mean(axis=0)[-100:]))\n",
    "        first_100_error.append( np.mean(pred_file.mean(axis=0)[:100]))\n",
    "        if np.mean(pred_file.mean(axis=0)[-100:]) > 0.1:\n",
    "            print (dir_path.split('/')[3],   np.mean(pred_file.mean(axis=0)[-100:]) )\n",
    "        \n",
    "        \n",
    "    # Sample data\n",
    "    data = last_100_error\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.hist(data, bins=80)\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel(f'{pattern_names[index]} Last 100 predictions MSE')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram')\n",
    "\n",
    "    plt.xlim(min(data), max(data))\n",
    "\n",
    "    # Displaying the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pattern_names = [\"DAE\", \"Koopman AE\", \"INN\", \"RNN\"]\n",
    "all_data = []  # Collect all data for common x-axis range\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))  # Create a 1x4 grid of subplots\n",
    "\n",
    "for index, ind_patter in enumerate(pattern_list):\n",
    "    avg_error = []\n",
    "    last_100_error = []\n",
    "    first_100_error = []\n",
    "\n",
    "    matched_directories = glob.glob(ind_patter)\n",
    "    for dir_path in matched_directories:\n",
    "        pred_file = np.load(dir_path)\n",
    "        avg_error.append(np.mean(pred_file.mean(axis=0)))\n",
    "        last_100_error.append(np.mean(pred_file.mean(axis=0)[-100:]))\n",
    "        first_100_error.append(np.mean(pred_file.mean(axis=0)[:100]))\n",
    "\n",
    "    all_data.extend(last_100_error)  # Collect data for common x-axis range\n",
    "\n",
    "    # Plotting the histogram\n",
    "    axes[index].hist(last_100_error, bins=80)\n",
    "\n",
    "    # Adding labels and title\n",
    "    axes[index].set_xlabel(f'{pattern_names[index]} Last 100 predictions MSE')\n",
    "    axes[index].set_ylabel('Frequency')\n",
    "    axes[index].set_title('Histogram')\n",
    "\n",
    "    axes[index].set_xlim(min(all_data), max(all_data))  # Set common x-axis range\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pattern_names = [\"DAE\", \"Koopman AE\", \"INN\", \"RNN\"]\n",
    "all_data = []  # Collect all data for common x-axis range\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))  # Create a 1x4 grid of subplots\n",
    "\n",
    "for index, ind_patter in enumerate(pattern_list):\n",
    "    avg_error = []\n",
    "    last_100_error = []\n",
    "    first_100_error = []\n",
    "\n",
    "    matched_directories = glob.glob(ind_patter)\n",
    "    for dir_path in matched_directories:\n",
    "        pred_file = np.load(dir_path)\n",
    "        avg_error.append(np.mean(pred_file.mean(axis=0)))\n",
    "        last_100_error.append(np.mean(pred_file.mean(axis=0)[-100:]))\n",
    "        first_100_error.append(np.mean(pred_file.mean(axis=0)[:100]))\n",
    "\n",
    "    all_data.extend(last_100_error)  # Collect data for common x-axis range\n",
    "\n",
    "    # Plotting the histogram\n",
    "    axes[index].hist(last_100_error, bins=80)\n",
    "\n",
    "    # Adding labels and title\n",
    "    axes[index].set_xlabel(f'{pattern_names[index]} Last 100 predictions MSE')\n",
    "    axes[index].set_ylabel('Frequency')\n",
    "    axes[index].set_title('Histogram')\n",
    "\n",
    "# Set common x-axis range\n",
    "x_min = min(all_data)\n",
    "x_max = max(all_data)\n",
    "for ax in axes:\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_error = []\n",
    "last_100_error = []\n",
    "first_100_error = []\n",
    "matched_directories = glob.glob(dae_pattern)\n",
    "for dir_path in matched_directories:\n",
    "    pred_file = np.load(dir_path)\n",
    "    avg_error.append(np.mean(pred_file.mean(axis=0)))\n",
    "    last_100_error.append(np.mean(pred_file.mean(axis=0)[-100:]))\n",
    "    first_100_error.append( np.mean(pred_file.mean(axis=0)[:100]))\n",
    "    \n",
    "print_statistics(avg_error, \"average Error\")\n",
    "print_statistics(last_100_error, \"last 100 prediction\")\n",
    "print_statistics(first_100_error, \"first 100 prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average error overarll pred: ', np.mean(pred_file.mean(axis=0)))\n",
    "print('Average error of last 100 pred: ', np.mean(pred_file.mean(axis=0)[-100:]))\n",
    "print('Average error of starting 100 pred: ', np.mean(pred_file.mean(axis=0)[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def print_statistics(lst, title):\n",
    "    average = round(statistics.mean(lst), 3)\n",
    "    minimum = round(min(lst), 3)\n",
    "    maximum = round(max(lst), 3)\n",
    "    stdev = round(statistics.stdev(lst), 3)\n",
    "\n",
    "    return [average, minimum, maximum, stdev]\n",
    "\n",
    "pattern_list = [dae_pattern, koopman_AE_pattern, INN_pattern, RNN_Patten]\n",
    "pattern_names = [\"DAE\", \"Koopman AE\", \"INN\", \"RNN\"]  # Update pattern names here\n",
    "\n",
    "master_avg_error = []\n",
    "master_last_100_error = []\n",
    "master_first_100_error = []\n",
    "\n",
    "for ind_pattern in pattern_list:\n",
    "    avg_error = []\n",
    "    last_100_error = []\n",
    "    first_100_error = []\n",
    "\n",
    "    matched_directories = glob.glob(ind_pattern)\n",
    "    for dir_path in matched_directories:\n",
    "        pred_file = np.load(dir_path)\n",
    "        avg_error.append(np.mean(pred_file.mean(axis=0)))\n",
    "        last_100_error.append(np.mean(pred_file.mean(axis=0)[-100:]))\n",
    "        first_100_error.append(np.mean(pred_file.mean(axis=0)[:100]))\n",
    "        \n",
    "    master_avg_error.append(avg_error)\n",
    "    master_last_100_error.append(last_100_error)\n",
    "    master_first_100_error.append(first_100_error)\n",
    "\n",
    "# Calculate statistics\n",
    "statistics_data = {}\n",
    "error_types = [\"Average Error (DAE, Koopman AE, INN, RNN)\", \"Last 100 predictions\", \"First 100 predictions\"]\n",
    "stat_names = [\"Average\", \"Minimum\", \"Maximum\", \"Standard Deviation\"]\n",
    "\n",
    "master_error_lists = [master_avg_error, master_last_100_error, master_first_100_error]\n",
    "\n",
    "for error_type, master_error in zip(error_types, master_error_lists):\n",
    "    statistics_data[error_type] = {}\n",
    "    for i, pattern_name in enumerate(pattern_names):\n",
    "        statistics_data[error_type][pattern_name] = {\n",
    "            \"Average\": print_statistics(master_error[i], \"average Error\")[0],\n",
    "            \"Minimum\": print_statistics(master_error[i], \"average Error\")[1],\n",
    "            \"Maximum\": print_statistics(master_error[i], \"average Error\")[2],\n",
    "            \"Standard Deviation\": print_statistics(master_error[i], \"average Error\")[3]\n",
    "        }\n",
    "\n",
    "# Define the table and its column titles\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Statistic\"] + error_types\n",
    "\n",
    "# Add rows to the table\n",
    "for stat in stat_names:\n",
    "    row = [stat]\n",
    "    for error_type in error_types:\n",
    "        values = [statistics_data[error_type][pattern_name][stat] for pattern_name in pattern_names]\n",
    "        row.append(values)\n",
    "    table.add_row(row)\n",
    "\n",
    "# Print the table\n",
    "print(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-confirmation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-manhattan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-joshua",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_100",
   "language": "python",
   "name": "main_100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
